{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7144d1",
   "metadata": {},
   "source": [
    "# Football Match Prediction - Exploratory Data Analysis\n",
    "\n",
    "This notebook explores the structure and patterns in football match data to inform feature engineering and model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2594e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append('../src')\n",
    "\n",
    "from spx.adapters.football.epl import EPLAdapter\n",
    "from spx.core.ratings import EloRatingSystem\n",
    "from spx.core.features import FeatureEngineer\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de08a57e",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "data_dir = Path('../tests/data')\n",
    "adapter = EPLAdapter(data_dir)\n",
    "\n",
    "# Load matches\n",
    "try:\n",
    "    matches = adapter.load_matches('2024-25')\n",
    "    print(f\"Loaded {len(matches)} matches\")\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    match_data = [match.dict() for match in matches]\n",
    "    df = pd.DataFrame(match_data)\n",
    "    \n",
    "    print(\"\\nDataFrame shape:\", df.shape)\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    # Create dummy data for demonstration\n",
    "    df = pd.DataFrame({\n",
    "        'date': pd.date_range('2024-08-11', periods=10),\n",
    "        'home_team': ['Arsenal', 'Chelsea', 'Man City'] * 3 + ['Brighton'],\n",
    "        'away_team': ['Wolves', 'Brighton', 'Arsenal'] * 3 + ['Everton'],\n",
    "        'home_goals': [2, 1, 3, 0, 2, 1, 1, 2, 0, 1],\n",
    "        'away_goals': [0, 1, 1, 2, 0, 3, 2, 1, 0, 0],\n",
    "        'outcome': ['H', 'D', 'H', 'A', 'H', 'A', 'A', 'H', 'D', 'H']\n",
    "    })\n",
    "    print(\"Using dummy data for demonstration\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa81b1",
   "metadata": {},
   "source": [
    "## 2. Goal Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze goal distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Home goals distribution\n",
    "axes[0, 0].hist(df['home_goals'], bins=range(0, 8), alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_title('Home Goals Distribution')\n",
    "axes[0, 0].set_xlabel('Goals')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Away goals distribution\n",
    "axes[0, 1].hist(df['away_goals'], bins=range(0, 8), alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].set_title('Away Goals Distribution')\n",
    "axes[0, 1].set_xlabel('Goals')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Total goals distribution\n",
    "total_goals = df['home_goals'] + df['away_goals']\n",
    "axes[1, 0].hist(total_goals, bins=range(0, 12), alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('Total Goals Distribution')\n",
    "axes[1, 0].set_xlabel('Total Goals')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Outcome distribution\n",
    "outcome_counts = df['outcome'].value_counts()\n",
    "axes[1, 1].bar(outcome_counts.index, outcome_counts.values)\n",
    "axes[1, 1].set_title('Match Outcome Distribution')\n",
    "axes[1, 1].set_xlabel('Outcome')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n=== GOAL STATISTICS ===\")\n",
    "print(f\"Average home goals: {df['home_goals'].mean():.2f}\")\n",
    "print(f\"Average away goals: {df['away_goals'].mean():.2f}\")\n",
    "print(f\"Average total goals: {total_goals.mean():.2f}\")\n",
    "\n",
    "print(\"\\n=== OUTCOME PERCENTAGES ===\")\n",
    "outcome_pcts = df['outcome'].value_counts(normalize=True) * 100\n",
    "for outcome, pct in outcome_pcts.items():\n",
    "    outcome_name = {'H': 'Home Win', 'D': 'Draw', 'A': 'Away Win'}[outcome]\n",
    "    print(f\"{outcome_name}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65955fd",
   "metadata": {},
   "source": [
    "## 3. Team Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f46460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze team performance\n",
    "teams = list(set(df['home_team'].unique()) | set(df['away_team'].unique()))\n",
    "print(f\"Teams in dataset: {len(teams)}\")\n",
    "print(teams)\n",
    "\n",
    "# Calculate basic team stats\n",
    "team_stats = []\n",
    "\n",
    "for team in teams:\n",
    "    home_matches = df[df['home_team'] == team]\n",
    "    away_matches = df[df['away_team'] == team]\n",
    "    \n",
    "    # Goals\n",
    "    goals_for = home_matches['home_goals'].sum() + away_matches['away_goals'].sum()\n",
    "    goals_against = home_matches['away_goals'].sum() + away_matches['home_goals'].sum()\n",
    "    \n",
    "    # Points\n",
    "    points = 0\n",
    "    games = 0\n",
    "    \n",
    "    for _, match in home_matches.iterrows():\n",
    "        games += 1\n",
    "        if match['outcome'] == 'H':\n",
    "            points += 3\n",
    "        elif match['outcome'] == 'D':\n",
    "            points += 1\n",
    "    \n",
    "    for _, match in away_matches.iterrows():\n",
    "        games += 1\n",
    "        if match['outcome'] == 'A':\n",
    "            points += 3\n",
    "        elif match['outcome'] == 'D':\n",
    "            points += 1\n",
    "    \n",
    "    if games > 0:\n",
    "        team_stats.append({\n",
    "            'team': team,\n",
    "            'games': games,\n",
    "            'points': points,\n",
    "            'ppg': points / games,\n",
    "            'goals_for': goals_for,\n",
    "            'goals_against': goals_against,\n",
    "            'goal_diff': goals_for - goals_against,\n",
    "            'gpg': goals_for / games,\n",
    "            'gapg': goals_against / games\n",
    "        })\n",
    "\n",
    "team_df = pd.DataFrame(team_stats).sort_values('ppg', ascending=False)\n",
    "print(\"\\n=== TEAM PERFORMANCE ===\")\n",
    "print(team_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed7a698",
   "metadata": {},
   "source": [
    "## 4. Home Advantage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd8cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze home advantage\n",
    "home_wins = (df['outcome'] == 'H').sum()\n",
    "draws = (df['outcome'] == 'D').sum()\n",
    "away_wins = (df['outcome'] == 'A').sum()\n",
    "total_games = len(df)\n",
    "\n",
    "print(\"=== HOME ADVANTAGE ANALYSIS ===\")\n",
    "print(f\"Home wins: {home_wins} ({home_wins/total_games*100:.1f}%)\")\n",
    "print(f\"Draws: {draws} ({draws/total_games*100:.1f}%)\")\n",
    "print(f\"Away wins: {away_wins} ({away_wins/total_games*100:.1f}%)\")\n",
    "\n",
    "# Goals by venue\n",
    "print(f\"\\nAverage home goals: {df['home_goals'].mean():.2f}\")\n",
    "print(f\"Average away goals: {df['away_goals'].mean():.2f}\")\n",
    "print(f\"Home advantage (goals): {df['home_goals'].mean() - df['away_goals'].mean():.2f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Outcome pie chart\n",
    "outcome_counts = [home_wins, draws, away_wins]\n",
    "labels = ['Home Win', 'Draw', 'Away Win']\n",
    "colors = ['green', 'gray', 'red']\n",
    "\n",
    "ax1.pie(outcome_counts, labels=labels, autopct='%1.1f%%', colors=colors)\n",
    "ax1.set_title('Match Outcomes')\n",
    "\n",
    "# Goals comparison\n",
    "venues = ['Home', 'Away']\n",
    "avg_goals = [df['home_goals'].mean(), df['away_goals'].mean()]\n",
    "\n",
    "ax2.bar(venues, avg_goals, color=['blue', 'orange'])\n",
    "ax2.set_title('Average Goals by Venue')\n",
    "ax2.set_ylabel('Average Goals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c696b05d",
   "metadata": {},
   "source": [
    "## 5. Elo Rating Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Elo rating system\n",
    "try:\n",
    "    elo_system = EloRatingSystem(\n",
    "        k_factor=20.0,\n",
    "        base_rating=1500.0,\n",
    "        home_advantage=30.0,\n",
    "        margin_multiplier=0.1\n",
    "    )\n",
    "    \n",
    "    # Update ratings with our sample data\n",
    "    ratings = elo_system.update_ratings(matches)\n",
    "    \n",
    "    # Show current ratings\n",
    "    current_ratings = elo_system.get_current_ratings()\n",
    "    \n",
    "    print(\"=== CURRENT ELO RATINGS ===\")\n",
    "    for team, rating in sorted(current_ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{team:<15}: {rating:.0f}\")\n",
    "    \n",
    "    # Plot rating evolution\n",
    "    rating_history = elo_system.get_rating_history()\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for team in teams[:6]:  # Plot top 6 teams\n",
    "        if team in rating_history:\n",
    "            dates = list(rating_history[team].keys())\n",
    "            ratings = list(rating_history[team].values())\n",
    "            \n",
    "            if dates:\n",
    "                plt.plot(dates, ratings, marker='o', label=team, linewidth=2)\n",
    "    \n",
    "    plt.title('Elo Rating Evolution')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Elo Rating')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with Elo analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88970d0",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ecf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature correlations\n",
    "if len(df) > 5:  # Need sufficient data\n",
    "    try:\n",
    "        # Create features\n",
    "        engineer = FeatureEngineer(lookback_games=3)\n",
    "        rating_dict = elo_system.get_rating_history() if 'elo_system' in locals() else None\n",
    "        \n",
    "        features_df = engineer.create_features(matches, rating_dict)\n",
    "        \n",
    "        print(\"=== FEATURE SUMMARY ===\")\n",
    "        print(f\"Features shape: {features_df.shape}\")\n",
    "        \n",
    "        # Show feature correlations with outcome\n",
    "        numeric_features = features_df.select_dtypes(include=[np.number]).columns\n",
    "        feature_cols = [col for col in numeric_features \n",
    "                       if col not in ['home_goals', 'away_goals']]\n",
    "        \n",
    "        if len(feature_cols) > 0:\n",
    "            # Encode outcome for correlation\n",
    "            features_df['outcome_numeric'] = features_df['outcome'].map({'A': 0, 'D': 1, 'H': 2})\n",
    "            \n",
    "            correlations = features_df[feature_cols + ['outcome_numeric']].corr()['outcome_numeric'].abs().sort_values(ascending=False)\n",
    "            \n",
    "            print(\"\\nFeature correlations with outcome:\")\n",
    "            for feature, corr in correlations[:-1].items():  # Exclude self-correlation\n",
    "                print(f\"{feature:<25}: {corr:.3f}\")\n",
    "            \n",
    "            # Plot correlation heatmap\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            corr_matrix = features_df[feature_cols].corr()\n",
    "            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "            plt.title('Feature Correlation Matrix')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Show sample features\n",
    "        print(\"\\nSample features:\")\n",
    "        display_cols = ['home_team', 'away_team', 'outcome'] + feature_cols[:5]\n",
    "        print(features_df[display_cols].head().round(2))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with feature analysis: {e}\")\n",
    "else:\n",
    "    print(\"Insufficient data for feature analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc63a4",
   "metadata": {},
   "source": [
    "## 7. Scoreline Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d6f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze scoreline patterns\n",
    "scorelines = df['home_goals'].astype(str) + '-' + df['away_goals'].astype(str)\n",
    "scoreline_counts = scorelines.value_counts().head(10)\n",
    "\n",
    "print(\"=== MOST COMMON SCORELINES ===\")\n",
    "for scoreline, count in scoreline_counts.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"{scoreline}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# Create scoreline heatmap\n",
    "max_goals = min(6, max(df['home_goals'].max(), df['away_goals'].max()))\n",
    "scoreline_matrix = np.zeros((max_goals + 1, max_goals + 1))\n",
    "\n",
    "for _, match in df.iterrows():\n",
    "    h_goals = min(match['home_goals'], max_goals)\n",
    "    a_goals = min(match['away_goals'], max_goals)\n",
    "    scoreline_matrix[h_goals, a_goals] += 1\n",
    "\n",
    "# Normalize to percentages\n",
    "scoreline_matrix = scoreline_matrix / len(df) * 100\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(scoreline_matrix, annot=True, fmt='.1f', cmap='Blues',\n",
    "            xticklabels=range(max_goals + 1),\n",
    "            yticklabels=range(max_goals + 1))\n",
    "plt.title('Scoreline Frequency Heatmap (%)')\n",
    "plt.xlabel('Away Goals')\n",
    "plt.ylabel('Home Goals')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec87e30a",
   "metadata": {},
   "source": [
    "## 8. Model Performance Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple baseline predictions for evaluation framework\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "if len(df) > 10:\n",
    "    # Prepare simple features\n",
    "    X_simple = pd.DataFrame({\n",
    "        'home_advantage': [1] * len(df),\n",
    "        'home_goals_avg': df['home_goals'].expanding().mean().shift(1).fillna(1.5),\n",
    "        'away_goals_avg': df['away_goals'].expanding().mean().shift(1).fillna(1.2)\n",
    "    })\n",
    "    \n",
    "    y = df['outcome'].map({'A': 0, 'D': 1, 'H': 2})\n",
    "    \n",
    "    # Train dummy classifier\n",
    "    dummy = DummyClassifier(strategy='prior')\n",
    "    dummy.fit(X_simple[:-2], y[:-2])  # Leave last 2 for \"prediction\"\n",
    "    \n",
    "    # \"Predict\" on last 2 matches\n",
    "    y_pred = dummy.predict(X_simple[-2:])\n",
    "    y_true = y[-2:]\n",
    "    \n",
    "    print(\"=== BASELINE MODEL PERFORMANCE ===\")\n",
    "    print(\"This shows the evaluation framework structure\")\n",
    "    print(f\"Predictions: {y_pred}\")\n",
    "    print(f\"Actual: {y_true.values}\")\n",
    "    \n",
    "    # Show probabilities\n",
    "    y_proba = dummy.predict_proba(X_simple[-2:])\n",
    "    print(\"\\nProbability predictions:\")\n",
    "    for i, (pred_probs, true_outcome) in enumerate(zip(y_proba, y_true)):\n",
    "        print(f\"Match {i+1}: Away={pred_probs[0]:.3f}, Draw={pred_probs[1]:.3f}, Home={pred_probs[2]:.3f} (True: {true_outcome})\")\n",
    "\n",
    "else:\n",
    "    print(\"Insufficient data for model evaluation demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31adb0",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This EDA provides insights for:\n",
    "\n",
    "1. **Feature Engineering**: Form metrics, Elo ratings, home advantage\n",
    "2. **Model Development**: XGBoost for outcomes, Poisson for scorelines\n",
    "3. **Evaluation Framework**: Calibration plots, Brier scores, log loss\n",
    "4. **Simulation Setup**: Monte Carlo with realistic distributions\n",
    "\n",
    "To continue:\n",
    "- Run `spx ingest` to process full datasets\n",
    "- Run `spx train` to build production models\n",
    "- Run `spx simulate` for season predictions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
